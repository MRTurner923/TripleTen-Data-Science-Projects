{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "<div style=\"border:solid blue 2px; padding: 20px\">\n\n**Overall Summary of the Project**\n\nHi Michael,\n\n**Overall**, you\u2019ve built a solid end-to-end classification pipeline that:\n- Splits data into 60/20/20 train/valid/test  \n- Tunes a Decision Tree (depth, leaf, split)  \n- Tunes two Random Forest variants  \n- Compares test accuracies and picks the best trade-off model  \n\nYour top Random Forest achieved ~0.84 accuracy, comfortably above the 0.75 target.  \n\n---\n\n**\ud83d\udc4d Strengths**\n    \n- Clear 3:1:1 splitting and reproducible `random_state`  \n- Thorough hyperparameter search for Decision Tree and Random Forest  \n- Uses the held-out test set to report final model accuracy  \n- Thoughtful discussion of speed vs. accuracy trade-off  \n\n---\n\n**\u26a0\ufe0f Areas for improvement**\n\n1. **Leakage in Decision Tree tuning**  \n   In your Decision Tree loop you scored on the **test** set rather than the validation set. That means your \u201cbest_result\u201d was chosen using test data\u2014data that should remain unseen until the final evaluation.  \n   - **Fix**: Use `features_valid`/`target_valid` to pick hyperparameters, then evaluate the chosen model once on `features_test`.\n\n2. **Baseline sanity check**  \n   We need to confirm that your best model beats a trivial baseline (e.g. always predict the majority class).  \n   - **Add** after your final test evaluation:  \n     <code>\n     from sklearn.dummy import DummyClassifier  \n     dummy = DummyClassifier(strategy=\"most_frequent\", random_state=2356)  \n     dummy.fit(features_train, target_train)  \n     print(\"Baseline accuracy:\", dummy.score(features_test, target_test))  \n     </code>  \n\n3. **Explicit final test evaluation**  \n   While you reported test accuracies in loops, please retrain your chosen model on **train+validation** and then report its single accuracy on `features_test`. This ensures no hyperparameter information leaked from test.  \n\n4. **Clear model\u2010selection code**  \n   Your loops mix \u201cbest_model\u201d and \u201cbest_est\u201d variables. For clarity, track each model\u2019s name and accuracy in a dict, then pick the best.  \n\n---\n\n**\u2705 What\u2019s required for approval**\n\n- **Retune Decision Tree on validation only**, not test  \n- **Add baseline DummyClassifier** accuracy on the test set  \n- **Retrain final chosen model on train+valid** and report its single test accuracy  \n\nOnce you make those changes, your project will fully meet the criteria. Let me know if you have any questions!  "}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-info\">\nHello, I retuned my Decision Tree Classifier to the validation dataset, not the test, I added my baseline Dummy model, and trained my chosen model as a final model on both the training and validation sets, is there anything I missed in these before my project is approved?\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div style=\"border:solid blue 2px; padding: 20px\">\n\n**Overall Summary of the Project Iter 2**\n\nHi Michael, thanks for the changes! Your project looks perfect, congrats on your approval :)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "# Project 7: Introduction to Machine Learning"}, {"cell_type": "markdown", "metadata": {}, "source": "## Importing and analyzing the dataset"}, {"cell_type": "markdown", "metadata": {}, "source": "In this project I'll be analyzing Megaline customer behavior to build a model that can recommend one of Megaline's new plans: Smart or Ultra. The data I'm working with contains behavior (calls, call duration in minutes, messages sent, and internet traffic in MB used) for a number of Megaline customers, as well as a Boolean declaring if they are on the Ultra plan or not. I'll be looking to develop a model with an accuracy value of at least 0.75 for this analysis. Because I'm looking to understand which category (plan) a user falls into, I'll be using classification models for this analysis."}, {"cell_type": "code", "execution_count": 13, "metadata": {"trusted": true}, "outputs": [], "source": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.dummy import DummyClassifier\nfrom time import time\nimport numpy as np"}, {"cell_type": "code", "execution_count": 14, "metadata": {"trusted": true}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>calls</th>\n      <th>minutes</th>\n      <th>messages</th>\n      <th>mb_used</th>\n      <th>is_ultra</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.0</td>\n      <td>311.90</td>\n      <td>83.0</td>\n      <td>19915.42</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85.0</td>\n      <td>516.75</td>\n      <td>56.0</td>\n      <td>22696.96</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>77.0</td>\n      <td>467.66</td>\n      <td>86.0</td>\n      <td>21060.45</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106.0</td>\n      <td>745.53</td>\n      <td>81.0</td>\n      <td>8437.39</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>66.0</td>\n      <td>418.74</td>\n      <td>1.0</td>\n      <td>14502.75</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   calls  minutes  messages   mb_used  is_ultra\n0   40.0   311.90      83.0  19915.42         0\n1   85.0   516.75      56.0  22696.96         0\n2   77.0   467.66      86.0  21060.45         0\n3  106.0   745.53      81.0   8437.39         1\n4   66.0   418.74       1.0  14502.75         0"}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": "df = pd.read_csv('/datasets/users_behavior.csv')\ndf.head()"}, {"cell_type": "code", "execution_count": 15, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3214 entries, 0 to 3213\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   calls     3214 non-null   float64\n 1   minutes   3214 non-null   float64\n 2   messages  3214 non-null   float64\n 3   mb_used   3214 non-null   float64\n 4   is_ultra  3214 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 125.7 KB\n"}], "source": "df.info()"}, {"cell_type": "markdown", "metadata": {}, "source": "Calls and messages are both floats in the dataset, may be something to come back to and change to int for analysis later on. Looks like there aren't any missing values either, but I'll still check for and remove any duplicates"}, {"cell_type": "code", "execution_count": 16, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "0"}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": "df.duplicated().sum()"}, {"cell_type": "markdown", "metadata": {}, "source": "No duplicates found, let's get started on the model!"}, {"cell_type": "markdown", "metadata": {}, "source": "## Building the Models"}, {"cell_type": "code", "execution_count": 17, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "(3214, 4) (3214,)\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>calls</th>\n      <th>minutes</th>\n      <th>messages</th>\n      <th>mb_used</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.0</td>\n      <td>311.90</td>\n      <td>83.0</td>\n      <td>19915.42</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85.0</td>\n      <td>516.75</td>\n      <td>56.0</td>\n      <td>22696.96</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>77.0</td>\n      <td>467.66</td>\n      <td>86.0</td>\n      <td>21060.45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106.0</td>\n      <td>745.53</td>\n      <td>81.0</td>\n      <td>8437.39</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>66.0</td>\n      <td>418.74</td>\n      <td>1.0</td>\n      <td>14502.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   calls  minutes  messages   mb_used\n0   40.0   311.90      83.0  19915.42\n1   85.0   516.75      56.0  22696.96\n2   77.0   467.66      86.0  21060.45\n3  106.0   745.53      81.0   8437.39\n4   66.0   418.74       1.0  14502.75"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "features = df.drop(['is_ultra'], axis = 1)\ntarget = df['is_ultra']\nprint(features.shape, target.shape)\nfeatures.head()"}, {"cell_type": "code", "execution_count": 18, "metadata": {"trusted": true}, "outputs": [], "source": "features_train, features_temporary, target_train, target_temporary = train_test_split(features, target, test_size = 0.4, random_state = 2356)\nfeatures_valid, features_test, target_valid, target_test = train_test_split(features_temporary, target_temporary, test_size = 0.5, random_state = 2356)"}, {"cell_type": "code", "execution_count": 19, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "(1928, 4) (1928,)\n\n(643, 4) (643,) (643, 4) (643,)\n"}], "source": "target_test = target_test.values\nprint(features_train.shape, target_train.shape)\nprint()\nprint(features_valid.shape, target_valid.shape, features_test.shape, target_test.shape)"}, {"cell_type": "markdown", "metadata": {}, "source": "3:1:1 ratio on the splits, 60% to training, and 20% each to test and validation sets"}, {"cell_type": "markdown", "metadata": {}, "source": "### Model 1: Decision Tree Classifier"}, {"cell_type": "code", "execution_count": 20, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Accuracy of the best model: 0.8320373250388803 Training time (s): 1.486004114151001\n"}], "source": "best_model = None\nbest_result = 0\nstart_time = time()\nfor depth in range(1,11):\n        for leaf in range(1,7,2):\n            for split in range(2, 21, 2):\n                model = DecisionTreeClassifier(\n                        random_state = 2356,\n                        max_depth = depth,\n                        min_samples_leaf = leaf, \n                        min_samples_split = split\n                )\n                model.fit(features_train, target_train)\n                test_predictions = model.predict(features_valid)\n                result = accuracy_score(target_valid, test_predictions)\n                if result > best_result:\n                    best_model = model\n                    best_result = result\ntraining_time = time() - start_time\nprint('Accuracy of the best model:', best_result, 'Training time (s):', training_time)"}, {"cell_type": "markdown", "metadata": {}, "source": "The model above took just under 1.5 seconds to come back with a resulting accuracy of just over 0.83, 8% higher than our accuracy threshold!"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-info\">\nChanged test_predictions to utilize the features_valid set and the result variable to test accuracy_score using target_valid instead of test_valid, accuracy improved by 2 points and speed was nearly identical\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "### Model 2: Random Forest Classifier"}, {"cell_type": "code", "execution_count": 9, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Accuracy of the best model: 0.8367029548989113 Training time (s): 20.421031951904297\n"}], "source": "best_score = 0\nbest_est = 0\nstart_time = time()\nfor est in range(1,21):\n    for depth in range(1,11):\n        for leaf in range(1, 11, 2):\n            model = RandomForestClassifier(\n                random_state = 2356,\n                n_estimators = est,\n                max_depth = depth,\n                min_samples_leaf = leaf,\n                )\n            model.fit(features_train, target_train)\n            score = model.score(features_valid, target_valid)\n            if score > best_score:\n                best_score = score\n                best_est = est\ntraining_time = time() - start_time\nprint('Accuracy of the best model:', best_score,'Training time (s):', training_time)"}, {"cell_type": "markdown", "metadata": {}, "source": "The model above took just under 21 seconds to result in an accuracy of roughly 0.837, only marginally higher than the last model but took over 10x longer to find the result."}, {"cell_type": "markdown", "metadata": {}, "source": "### Model 3: Random Forest Classifier with split samples"}, {"cell_type": "code", "execution_count": 10, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Accuracy of the best model: 0.8413685847589425 Training time (s): 204.13188672065735\n"}], "source": "best_score = 0\nbest_est = 0\nstart_time = time()\nfor est in range(1,21):\n    for depth in range(1,11):\n        for leaf in range(1, 11, 2):\n            for split in range(2, 21, 2):\n                model = RandomForestClassifier(\n                    random_state = 2356,\n                    n_estimators = est,\n                    max_depth = depth,\n                    min_samples_leaf = leaf,\n                    min_samples_split = split\n                )\n                model.fit(features_train, target_train)\n                score = model.score(features_valid, target_valid)\n                if score > best_score:\n                    best_score = score\n                    best_est = est\ntraining_time = time() - start_time\nprint('Accuracy of the best model:', best_score, 'Training time (s):', training_time)"}, {"cell_type": "markdown", "metadata": {}, "source": "This model took nearly 3 and a half minutes to result in an accuracy only marginally higher than the last result."}, {"cell_type": "markdown", "metadata": {}, "source": "### Sanity Check"}, {"cell_type": "code", "execution_count": 11, "metadata": {"scrolled": true, "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Baseline accuracy: 0.687402799377916\n"}], "source": "dummy = DummyClassifier(strategy = 'most_frequent', random_state = 2356)  \ndummy.fit(features_train, target_train)  \nprint('Baseline accuracy:', dummy.score(features_test, target_test))"}, {"cell_type": "markdown", "metadata": {}, "source": "The baseline accuracy result was under 70%. Compared to the models I utilized, this is a much lower result, while also being under the required threshold for this analysis."}, {"cell_type": "markdown", "metadata": {}, "source": "### Final Model Selection"}, {"cell_type": "code", "execution_count": 22, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Best parameters found:\nmax_depth: 7\nmin_samples_leaf: 5\nmin_samples_split: 2\nFinal test accuracy: 0.7884914463452566\n"}], "source": "best_params = {\n    'max_depth': best_model.get_params()['max_depth'],\n    'min_samples_leaf': best_model.get_params()['min_samples_leaf'],\n    'min_samples_split': best_model.get_params()['min_samples_split']\n}\n\nprint('Best parameters found:')\nprint(f\"max_depth: {best_params['max_depth']}\")\nprint(f\"min_samples_leaf: {best_params['min_samples_leaf']}\")\nprint(f\"min_samples_split: {best_params['min_samples_split']}\")\n\nfinal_model = DecisionTreeClassifier(\n    random_state=2356,\n    max_depth=best_params['max_depth'],\n    min_samples_leaf=best_params['min_samples_leaf'],\n    min_samples_split=best_params['min_samples_split']\n)\n\nx_train_full = np.concatenate([features_train, features_valid])\ny_train_full = np.concatenate([target_train, target_valid])\n\nfinal_model.fit(x_train_full, y_train_full)\n\nfinal_test_score = final_model.score(features_test, target_test)\nprint(f'Final test accuracy: {final_test_score}')"}, {"cell_type": "markdown", "metadata": {}, "source": "Based on final test accuracy, we see a slight, but expected, dropoff in the accuracy value. However, falling from just over 0.83 to just under 0.79 isn't too bad at all!"}, {"cell_type": "markdown", "metadata": {}, "source": "## Conclusion"}, {"cell_type": "markdown", "metadata": {}, "source": "As mentioned in the introduction to this project, to determine which category (plan) our users may fall into, I developed 3 different classification models to test. The first, a Decision Tree Classifier, was by far the fastest, but also offered the lowest level of accuracy out of all 3, 0.832. The second, a Random Forest Classifier, was middle of the road in terms of speed and accuracy, coming in at ~21 seconds and 0.837 accuracy score. The third and final model I developed, a Random Forest Classifier that used the min_samples_split hyperparameter, produced the highest accuracy score of the bunch, but also took an extremely long time to produce that result, and the accuracy was only 0.004 higher than the first Random Forest model.\n\nIn context of all the models tested so far, I believe the first model, the Decision Tree Classifier, shows the best combination of efficiency and accuracy, therefore I would recommend using that model to recommend either the Smart or Ultra plan to our Megaline customers. A quick sanity check on a dummy model shows that our baseline accuracy is under 70%, well under the results of all of my models and the threshold for this analysis.\n\nThe final model selection shows the best parameters chosen for the Decision Tree Classifier model, and when tested on \"new\" data, it still resulted in an accuracy of ~79%, which is to be expected when tested with that new data, giving us a better estimate of how this model would perform in a real world scenario.\n\nI do believe the speed of these models should be taken with a grain of salt, however, as my computer is certainly not the biggest powerhouse available. Maybe better hardware shortens the gap in terms of speed to where the third model becomes more viable, or maybe speed of the result doesn't factor in to which model is decided on. All things to consider before making a final selection, but based on the available resources, my choice would be model #1."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-info\">\nI tried to develop a dictionary to assess the following feedback:\nClear model\u2010selection code\nYour loops mix \u201cbest_model\u201d and \u201cbest_est\u201d variables. For clarity, track each model\u2019s name and accuracy in a dict, then pick the best.\n\nBut couldn't quite understand what was being asked of me, is there a different way of explaining this so I can try to learn that method as well?\n</div>"}], "metadata": {"ExecuteTimeLog": [{"duration": 802, "start_time": "2025-04-30T23:17:18.553Z"}, {"duration": 19, "start_time": "2025-04-30T23:17:33.145Z"}, {"duration": 10, "start_time": "2025-04-30T23:17:37.966Z"}, {"duration": 5, "start_time": "2025-04-30T23:17:52.896Z"}, {"duration": 9, "start_time": "2025-04-30T23:17:58.044Z"}, {"duration": 5, "start_time": "2025-04-30T23:18:05.576Z"}, {"duration": 4, "start_time": "2025-04-30T23:18:11.475Z"}, {"duration": 1460, "start_time": "2025-04-30T23:18:48.083Z"}, {"duration": 1445, "start_time": "2025-04-30T23:19:07.049Z"}, {"duration": 6, "start_time": "2025-04-30T23:21:09.462Z"}, {"duration": 4, "start_time": "2025-04-30T23:21:21.664Z"}, {"duration": 20580, "start_time": "2025-04-30T23:21:41.488Z"}, {"duration": 207554, "start_time": "2025-04-30T23:23:11.848Z"}, {"duration": 830, "start_time": "2025-05-01T00:54:37.380Z"}, {"duration": 26, "start_time": "2025-05-01T00:54:38.213Z"}, {"duration": 9, "start_time": "2025-05-01T00:54:38.241Z"}, {"duration": 5, "start_time": "2025-05-01T00:54:38.252Z"}, {"duration": 8, "start_time": "2025-05-01T00:54:38.258Z"}, {"duration": 20, "start_time": "2025-05-01T00:54:38.268Z"}, {"duration": 4, "start_time": "2025-05-01T00:54:38.289Z"}, {"duration": 1494, "start_time": "2025-05-01T00:54:38.295Z"}, {"duration": 20619, "start_time": "2025-05-01T00:54:39.792Z"}, {"duration": 207003, "start_time": "2025-05-01T00:55:00.414Z"}, {"duration": 934, "start_time": "2025-05-01T03:45:01.016Z"}, {"duration": 20, "start_time": "2025-05-01T03:45:01.952Z"}, {"duration": 12, "start_time": "2025-05-01T03:45:01.974Z"}, {"duration": 5, "start_time": "2025-05-01T03:45:01.988Z"}, {"duration": 12, "start_time": "2025-05-01T03:45:02.012Z"}, {"duration": 6, "start_time": "2025-05-01T03:45:02.026Z"}, {"duration": 6, "start_time": "2025-05-01T03:45:02.034Z"}, {"duration": 1551, "start_time": "2025-05-01T03:45:02.042Z"}, {"duration": 24669, "start_time": "2025-05-01T03:45:03.596Z"}, {"duration": 807, "start_time": "2025-05-01T23:12:45.121Z"}, {"duration": 18, "start_time": "2025-05-01T23:12:46.576Z"}, {"duration": 10, "start_time": "2025-05-01T23:12:46.975Z"}, {"duration": 6, "start_time": "2025-05-01T23:12:49.392Z"}, {"duration": 9, "start_time": "2025-05-01T23:12:50.862Z"}, {"duration": 6, "start_time": "2025-05-01T23:12:52.027Z"}, {"duration": 3, "start_time": "2025-05-01T23:12:52.893Z"}, {"duration": 1477, "start_time": "2025-05-01T23:12:55.495Z"}, {"duration": 20458, "start_time": "2025-05-01T23:15:04.356Z"}, {"duration": 206410, "start_time": "2025-05-01T23:16:22.674Z"}, {"duration": 3, "start_time": "2025-05-01T23:24:37.948Z"}, {"duration": 5, "start_time": "2025-05-01T23:25:10.745Z"}, {"duration": 261, "start_time": "2025-05-02T00:00:46.743Z"}, {"duration": 3, "start_time": "2025-05-02T00:00:51.352Z"}, {"duration": 1472, "start_time": "2025-05-02T00:00:54.437Z"}, {"duration": 8, "start_time": "2025-05-02T00:01:57.978Z"}, {"duration": 20510, "start_time": "2025-05-02T00:02:10.897Z"}, {"duration": 742, "start_time": "2025-05-02T00:04:11.086Z"}, {"duration": 16, "start_time": "2025-05-02T00:04:11.831Z"}, {"duration": 9, "start_time": "2025-05-02T00:04:11.848Z"}, {"duration": 5, "start_time": "2025-05-02T00:04:11.859Z"}, {"duration": 9, "start_time": "2025-05-02T00:04:11.866Z"}, {"duration": 34, "start_time": "2025-05-02T00:04:11.877Z"}, {"duration": 3, "start_time": "2025-05-02T00:04:11.913Z"}, {"duration": 1485, "start_time": "2025-05-02T00:04:11.918Z"}, {"duration": 20429, "start_time": "2025-05-02T00:04:13.405Z"}, {"duration": 204136, "start_time": "2025-05-02T00:04:33.837Z"}, {"duration": 5, "start_time": "2025-05-02T00:07:57.974Z"}, {"duration": 276, "start_time": "2025-05-02T00:12:00.684Z"}, {"duration": 2, "start_time": "2025-05-02T00:12:11.518Z"}, {"duration": 12, "start_time": "2025-05-02T00:12:12.773Z"}, {"duration": 8, "start_time": "2025-05-02T00:12:13.120Z"}, {"duration": 5, "start_time": "2025-05-02T00:12:13.768Z"}, {"duration": 9, "start_time": "2025-05-02T00:12:14.732Z"}, {"duration": 6, "start_time": "2025-05-02T00:12:15.950Z"}, {"duration": 3, "start_time": "2025-05-02T00:12:16.236Z"}, {"duration": 1490, "start_time": "2025-05-02T00:12:18.353Z"}, {"duration": 11, "start_time": "2025-05-02T00:12:24.112Z"}, {"duration": 12, "start_time": "2025-05-02T00:16:57.896Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}