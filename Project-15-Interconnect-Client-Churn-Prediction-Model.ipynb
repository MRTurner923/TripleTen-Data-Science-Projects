{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Reviewer‚Äôs comments ‚Äì Iteration 1:</b><br>\n",
    "\n",
    "  Hello Michael!,\n",
    "  \n",
    "I am Alexangel, your reviewer,\n",
    "  \n",
    "Another project successfully completed - well done! üèÜ Your consistent effort and progress are truly commendable.\n",
    "\n",
    "Our team is here to help you keep pushing forward and honing your skills as you advance through the program.\n",
    "\n",
    "My comments are marked as `Reviewer's comment`. You can contact me via Tripleten Hub for further feedback. This information is described below.\n",
    "\n",
    "**What Was Great**:\n",
    "- Excellent job on following the structure of the project.\n",
    "- You‚Äôve shown strong skills in testing the models in this project.\n",
    "\n",
    "**Tips for Future Projects**:\n",
    "- Consider adding brief comments after the analysis or graph of every dataframe to make your work even more integral.\n",
    "\n",
    "Congratulations again on your accomplishment! Each project you complete adds to your growing expertise, and it‚Äôs exciting to see you make such great strides. Keep up the great work! üéØ\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "***Name of the reviewer***: Alexangel Bracho\n",
    "\n",
    "***Reviewer's Tripleten Hub  link*** : [reviewer's link](https://hub.tripleten.com/u/6b1cbe37)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Model Testing and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_df = pd.read_csv('/datasets/final_provider/contract.csv')\n",
    "personal_df = pd.read_csv('/datasets/final_provider/personal.csv')\n",
    "internet_df = pd.read_csv('/datasets/final_provider/internet.csv')\n",
    "phone_df = pd.read_csv('/datasets/final_provider/phone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_df = contract_df.rename(columns = {'customerID':'customer_id', 'BeginDate':'begin_date', 'EndDate':'end_date',\n",
    "                                            'Type':'type', 'PaperlessBilling':'paperless_billing', 'PaymentMethod':'payment_method',\n",
    "                                           'MonthlyCharges':'monthly_charges', 'TotalCharges':'total_charges'})\n",
    "personal_df = personal_df.rename(columns = {'customerID':'customer_id', 'SeniorCitizen':'senior_citizen', 'Partner':'partner',\n",
    "                                           'Dependents':'dependents'})\n",
    "internet_df = internet_df.rename(columns = {'customerID':'customer_id', 'InternetService':'internet_service', \n",
    "                                            'OnlineSecurity':'online_security', 'OnlineBackup':'online_backup',\n",
    "                                           'DeviceProtection':'device_protection', 'TechSupport':'tech_support',\n",
    "                                           'StreamingTV':'streaming_tv', 'StreamingMovies':'streaming_movies'})\n",
    "phone_df = phone_df.rename(columns = {'customerID':'customer_id', 'MultipleLines':'multiple_lines'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = contract_df.merge(personal_df, on = 'customer_id', how = 'left')\n",
    "merge2 = internet_df.merge(phone_df, on = 'customer_id', how = 'left')\n",
    "df = merge1.merge(merge2, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_columns = ['internet_service', 'online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv',\n",
    "                   'streaming_movies']\n",
    "df[internet_columns] = df[internet_columns].fillna('No internet service')\n",
    "\n",
    "df['multiple_lines'] = df['multiple_lines'].fillna('No phone service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_charges'] = pd.to_numeric(df['total_charges'], errors = 'coerce')\n",
    "df['total_charges'] = df['total_charges'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['begin_date'] = pd.to_datetime(df['begin_date'])\n",
    "df['end_date'] = pd.to_datetime(df['end_date'].replace(\"No\", pd.NaT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['partner'] = df['partner'].replace('Yes', 1)\n",
    "df['partner'] = df['partner'].replace('No', 0)\n",
    "df['paperless_billing'] = df['paperless_billing'].replace('Yes', 1)\n",
    "df['paperless_billing'] = df['paperless_billing'].replace('No', 0)\n",
    "df['dependents'] = df['dependents'].replace('Yes', 1)\n",
    "df['dependents'] = df['dependents'].replace('No', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.to_datetime(\"2020-02-01\")\n",
    "df['tenure_days'] = (df['end_date'].fillna(cutoff_date) - df['begin_date']).dt.days\n",
    "df['tenure_months'] = df['tenure_days'] // 30\n",
    "df['churn'] = df['end_date'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7043 entries, 0 to 7042\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   customer_id        7043 non-null   object        \n",
      " 1   begin_date         7043 non-null   datetime64[ns]\n",
      " 2   end_date           1869 non-null   datetime64[ns]\n",
      " 3   type               7043 non-null   object        \n",
      " 4   paperless_billing  7043 non-null   int64         \n",
      " 5   payment_method     7043 non-null   object        \n",
      " 6   monthly_charges    7043 non-null   float64       \n",
      " 7   total_charges      7043 non-null   float64       \n",
      " 8   gender             7043 non-null   object        \n",
      " 9   senior_citizen     7043 non-null   int64         \n",
      " 10  partner            7043 non-null   int64         \n",
      " 11  dependents         7043 non-null   int64         \n",
      " 12  internet_service   7043 non-null   object        \n",
      " 13  online_security    7043 non-null   object        \n",
      " 14  online_backup      7043 non-null   object        \n",
      " 15  device_protection  7043 non-null   object        \n",
      " 16  tech_support       7043 non-null   object        \n",
      " 17  streaming_tv       7043 non-null   object        \n",
      " 18  streaming_movies   7043 non-null   object        \n",
      " 19  multiple_lines     7043 non-null   object        \n",
      " 20  tenure_days        7043 non-null   int64         \n",
      " 21  tenure_months      7043 non-null   int64         \n",
      " 22  churn              7043 non-null   int64         \n",
      "dtypes: datetime64[ns](2), float64(2), int64(7), object(12)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 19) (7043,)\n"
     ]
    }
   ],
   "source": [
    "customer_ids = df['customer_id']\n",
    "features = df.drop(['customer_id', 'begin_date', 'end_date', 'churn'], axis = 1)\n",
    "target = df['churn']\n",
    "print(features.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = features.select_dtypes(include = ['object']).columns\n",
    "num_cols = ['monthly_charges', 'total_charges', 'tenure_months', 'tenure_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4225, 19) (4225,)\n",
      "\n",
      "(1409, 19) (1409,) (1409, 19) (1409,)\n"
     ]
    }
   ],
   "source": [
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size = 0.4, random_state = 2356)\n",
    "features_test, features_valid, target_test, target_valid = train_test_split(features_temp, target_temp, test_size = 0.5, random_state = 2356)\n",
    "print(features_train.shape, target_train.shape)\n",
    "print()\n",
    "print(features_valid.shape, target_valid.shape, features_test.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting our data into a training, test, and validation set at a typical 3:1:1 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [('num', StandardScaler(), num_cols), ('cat', OneHotEncoder(drop = 'first'), cat_cols)\n",
    "                   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5174\n",
       "True     1869\n",
       "Name: end_date, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determining class weights and counts for scale_pos_weight use in XGB and LGBM\n",
    "class_counts = df['end_date'].notna().value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight = class_counts[0] / class_counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_boost_weights = [(len(df) / (2 * class_counts[0])), (len(df) / (2 * class_counts[1]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Evaluation of Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.892073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.890113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.886889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.854115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.845545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.724422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ROC-AUC\n",
       "Model                        \n",
       "LightGBM             0.892073\n",
       "XGBoost              0.890113\n",
       "CatBoost             0.886889\n",
       "Random Forest        0.854115\n",
       "Logistic Regression  0.845545\n",
       "Decision Tree        0.724422"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'Logistic Regression': LogisticRegression(class_weight = 'balanced',\n",
    "                                                                    solver = 'liblinear',\n",
    "                                                                    random_state = 2356\n",
    "                                                   ),\n",
    "          'Decision Tree': DecisionTreeClassifier(class_weight = 'balanced',\n",
    "                                                  random_state = 2356\n",
    "                                                 ),\n",
    "          'Random Forest': RandomForestClassifier(class_weight = 'balanced',\n",
    "                                                  random_state = 2356\n",
    "                                                 ),\n",
    "          'XGBoost': XGBClassifier(scale_pos_weight = scale_pos_weight,\n",
    "                                   use_label_encoder = False,\n",
    "                                   eval_metric = 'auc',\n",
    "                                   random_state = 2356\n",
    "                                  ),\n",
    "          'LightGBM': LGBMClassifier(scale_pos_weight = scale_pos_weight,\n",
    "                                     random_state = 2356\n",
    "                                    ),\n",
    "          'CatBoost': CatBoostClassifier(class_weights = cat_boost_weights,\n",
    "                                         random_state = 2356,\n",
    "                                         verbose = 0\n",
    "                                        )\n",
    "         }\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor), ('classifier', model)\n",
    "    ])\n",
    "    pipeline.fit(features_train, target_train)\n",
    "    pred_prob = pipeline.predict_proba(features_valid)[:, 1]\n",
    "    auc = roc_auc_score(target_valid, pred_prob)\n",
    "    results[name] = auc\n",
    "    results_df = pd.DataFrame.from_dict(results, orient = 'index', columns = ['ROC-AUC'])\n",
    "    results_df.index.name = 'Model'\n",
    "    results_df = results_df.sort_values('ROC-AUC', ascending = False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the ROC-AUC scores of our models before cross-validation gives me a good idea of results to expect after CV. The models might not perform the exact same but this at least helps me understand which models are separating themselves from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_auc</th>\n",
       "      <th>std_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.885597</td>\n",
       "      <td>0.007435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.883571</td>\n",
       "      <td>0.009063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.883344</td>\n",
       "      <td>0.007506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.851195</td>\n",
       "      <td>0.014797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.846320</td>\n",
       "      <td>0.013522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.696199</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean_auc   std_auc\n",
       "XGBoost              0.885597  0.007435\n",
       "CatBoost             0.883571  0.009063\n",
       "LightGBM             0.883344  0.007506\n",
       "Logistic Regression  0.851195  0.014797\n",
       "Random Forest        0.846320  0.013522\n",
       "Decision Tree        0.696199  0.014131"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'Logistic Regression': LogisticRegression(class_weight = 'balanced',\n",
    "                                                                    solver = 'liblinear',\n",
    "                                                                    random_state = 2356\n",
    "                                                   ),\n",
    "          'Decision Tree': DecisionTreeClassifier(class_weight = 'balanced',\n",
    "                                                  random_state = 2356\n",
    "                                                 ),\n",
    "          'Random Forest': RandomForestClassifier(class_weight = 'balanced',\n",
    "                                                  random_state = 2356\n",
    "                                                 ),\n",
    "          'XGBoost': XGBClassifier(scale_pos_weight = scale_pos_weight,\n",
    "                                   use_label_encoder = False,\n",
    "                                   eval_metric = 'auc',\n",
    "                                   random_state = 2356\n",
    "                                  ),\n",
    "          'LightGBM': LGBMClassifier(scale_pos_weight = scale_pos_weight,\n",
    "                                     random_state = 2356\n",
    "                                    ),\n",
    "          'CatBoost': CatBoostClassifier(class_weights = cat_boost_weights,\n",
    "                                         random_state = 2356,\n",
    "                                         verbose = 0\n",
    "                                        )\n",
    "         }\n",
    "cross_val_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor), ('classifier', model)\n",
    "    ])\n",
    "    scores = cross_val_score(\n",
    "        pipeline,\n",
    "        features_train,\n",
    "        target_train,\n",
    "        cv = 5,\n",
    "        scoring = 'roc_auc'\n",
    "    )\n",
    "\n",
    "    cross_val_results[name] = {\n",
    "        'mean_auc': scores.mean(),\n",
    "        'std_auc': scores.std()\n",
    "    }\n",
    "cross_val_df = pd.DataFrame(cross_val_results).T\n",
    "cross_val_df = cross_val_df[['mean_auc', 'std_auc']]\n",
    "cross_val_df = cross_val_df.sort_values('mean_auc', ascending = False)\n",
    "cross_val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running cross-validation on the chosen models, the boosted models still performed the best, all showing mean ROC-AUC scores just over 0.88 and very minimal standard deviations. The simpler models like Logistic Regression and Random Forest performed well, and the Decision Tree Classifier was the poorest of the bunch, not even topping 0.7. For evaluating with the test set, I'll be using the 3 boosted models and comparing their performance against each other and the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Analysis of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.867685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.866738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.864549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ROC-AUC\n",
       "Model             \n",
       "CatBoost  0.867685\n",
       "LightGBM  0.866738\n",
       "XGBoost   0.864549"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'XGBoost': XGBClassifier(scale_pos_weight = scale_pos_weight,\n",
    "                                   use_label_encoder = False,\n",
    "                                   eval_metric = 'auc',\n",
    "                                   random_state = 2356\n",
    "                                  ),\n",
    "          'LightGBM': LGBMClassifier(scale_pos_weight = scale_pos_weight,\n",
    "                                     random_state = 2356\n",
    "                                    ),\n",
    "          'CatBoost': CatBoostClassifier(class_weights = cat_boost_weights,\n",
    "                                         random_state = 2356,\n",
    "                                         verbose = 0\n",
    "                                        )\n",
    "         }\n",
    "test_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor), ('classifier', model)\n",
    "    ])\n",
    "    pipeline.fit(features_train, target_train)\n",
    "    pred_prob = pipeline.predict_proba(features_test)[:, 1]\n",
    "    auc = roc_auc_score(target_test, pred_prob)\n",
    "    test_results[name] = auc\n",
    "    test_results_df = pd.DataFrame.from_dict(test_results, orient = 'index', columns = ['ROC-AUC'])\n",
    "    test_results_df.index.name = 'Model'\n",
    "    test_results_df = test_results_df.sort_values('ROC-AUC', ascending = False)\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After letting the models analyze the test data, the results are very promising! The CatBoost model gets a slight edge over LGBM, with XGB not too far behind. Knowing that a score closer to 1 is indicative of a stronger model, we have 3 very high quality choices on our hands with these boosted models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Good work so far with the `Solution Code`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
